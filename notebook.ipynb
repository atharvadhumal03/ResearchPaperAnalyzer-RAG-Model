{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "846d9a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30005882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Loading environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Fetching the API key\n",
    "gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "# Verifing the key loaded\n",
    "print(\"API Key loaded successfully!\" if gemini_api_key else \"API Key not found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60723633",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/atharvadhumal/Documents/MyCodingDocs/GitHub projects/Rough Work/Research Paper Analyzer - RAG Model/myVenv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini LLM initialized!\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# Initializing Gemini\n",
    "geminillm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\", \n",
    "    google_api_key=gemini_api_key,\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "print(\"Gemini LLM initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "223f877d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 28 pages\n",
      "\n",
      "First page content preview:\n",
      "Retrieval-Augmented Generation for\n",
      "Knowledge-Intensive NLP Tasks\n",
      "Patrick Lewis†‡, Ethan Perez⋆,\n",
      "Aleksandra Piktus†, Fabio Petroni†, Vladimir Karpukhin†, Naman Goyal†, Heinrich Küttler†,\n",
      "Mike Lewis†, Wen-tau Yih†, Tim Rocktäschel†‡, Sebastian Riedel†‡, Douwe Kiela†\n",
      "†Facebook AI Research;‡University College London;⋆New York University;\n",
      "plewis@fb.com\n",
      "Abstract\n",
      "Large pre-trained language models have been shown to store factual knowledge\n",
      "in their parameters, and achieve state-of-the-art results when ﬁ...\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "pdf_path = \"testPaper.pdf\" \n",
    "loader = PyPDFLoader(pdf_path)\n",
    "\n",
    "pages = loader.load_and_split()\n",
    "\n",
    "print(f\"Loaded {len(pages)} pages\\n\")\n",
    "print(f\"First page content preview:\\n{pages[0].page_content[:500]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c87ae9e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chunks - 116\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Creating a text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,        # chars per chunk\n",
    "    chunk_overlap=400,      # overlap between chunks\n",
    "    length_function=len,\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(pages)\n",
    "print(f\"total chunks - {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41664e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wc/rfc_yx2d3m3dt9v_17z_88fm0000gn/T/ipykernel_52348/2752605660.py:5: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  HuggingFaceembeddingsModel = HuggingFaceEmbeddings(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings created\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# Initializing embeddings model\n",
    "HuggingFaceembeddingsModel = HuggingFaceEmbeddings(\n",
    "       model_name=\"all-MiniLM-L6-v2\"\n",
    "   )\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=HuggingFaceembeddingsModel,\n",
    "    persist_directory=\"./chroma_db\"\n",
    ")\n",
    "\n",
    "print(\"embeddings created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1173a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of embeddings created: 116\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of embeddings created: {vectorstore._collection.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a439f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieval-Augmented Generation for\n",
      "Knowledge-Intensive NLP Tasks\n",
      "Patrick Lewis†‡, Ethan Perez⋆,\n",
      "Aleksandra Piktus†, Fabio Petroni†, Vladimir Karpukhin†, Naman Goyal†, Heinrich Küttler†,\n",
      "Mike Lewis†, W\n",
      "\n",
      "Embedding dimension: 384\n",
      "First 5 values: [-0.06688090413808823, -0.03467119485139847, -0.026010597124695778, 0.08180363476276398, 0.01612071320414543]\n"
     ]
    }
   ],
   "source": [
    "# Testing embeddings\n",
    "print(chunks[0].page_content[:200])\n",
    "sample_embedding = HuggingFaceembeddingsModel.embed_query(chunks[0].page_content)\n",
    "\n",
    "print(f\"\\nEmbedding dimension: {len(sample_embedding)}\")\n",
    "print(f\"First 5 values: {sample_embedding[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77bc3444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is this paper about?\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Chunk 1:\n",
      "speciﬁc by a large margin. Table 3 shows typical generations from each model.\n",
      "Jeopardy questions often contain two separate pieces of information, and RAG-Token may perform\n",
      "best because it can generate responses that combine content from several documents. Figure 2 shows\n",
      "an example. When generating \n",
      "...\n",
      "\n",
      "Chunk 2:\n",
      "RAG-S This 14th century work is divided into 3 sections: \"Inferno\", \"Purgatorio\" & \"Paradiso\"\n",
      "For 2-way classiﬁcation, we compare against Thorne and Vlachos [57], who train RoBERTa [35]\n",
      "to classify the claim as true or false given the gold evidence sentence. RAG achieves an accuracy\n",
      "within 2.7% of t\n",
      "...\n",
      "\n",
      "Chunk 3:\n",
      "Processing Systems 32, pages 3261–3275. Curran Associates, Inc., 2019. URL https://\n",
      "arxiv.org/abs/1905.00537.\n",
      "[62] Shuohang Wang, Mo Yu, Xiaoxiao Guo, Zhiguo Wang, Tim Klinger, Wei Zhang, Shiyu Chang,\n",
      "Gerry Tesauro, Bowen Zhou, and Jing Jiang. R3: Reinforced ranker-reader for open-domain\n",
      "question an\n",
      "...\n",
      "\n",
      "Chunk 4:\n",
      "2020. URL https://arxiv.org/abs/2004.07159.\n",
      "[5] Danqi Chen, Adam Fisch, Jason Weston, and Antoine Bordes. Reading Wikipedia to Answer\n",
      "Open-Domain Questions. In Proceedings of the 55th Annual Meeting of the Association for\n",
      "Computational Linguistics (Volume 1: Long Papers), pages 1870–1879, Vancouver,\n",
      "...\n",
      "\n",
      "Chunk 5:\n",
      "This observation suggests that the generator can complete the titles without depending on speciﬁc\n",
      "documents. In other words, the model’s parametric knowledge is sufﬁcient to complete the titles. We\n",
      "ﬁnd evidence for this hypothesis by feeding the BART-only baseline with the partial decoding\"The\n",
      "Sun. \n",
      "...\n"
     ]
    }
   ],
   "source": [
    "# Test similarity search\n",
    "query = \"What is this paper about?\"\n",
    "\n",
    "# Retrieve top 5 most relevant chunks\n",
    "relevant_chunks = vectorstore.similarity_search(query, k=5)\n",
    "\n",
    "print(f\"Query: {query}\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i, chunk in enumerate(relevant_chunks, 1):\n",
    "    print(f\"\\nChunk {i}:\")\n",
    "    print(chunk.page_content[:300])\n",
    "    print(\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17475ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to join documents\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfb31492",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic import hub\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | geminillm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35c21bca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The research paper was published in 2020. Its URL is https://arxiv.org/abs/2004.07159.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"When was the research paper published?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2439dc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I apologize, but the provided context does not contain information about the authors of this specific paper. It lists authors for several referenced papers, but not for the paper itself.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"Who are the authors of this paper?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22ea8900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RAG-Token performs well on Jeopardy questions by combining content from multiple documents. The paper finds that after the first token of a title is generated, the document posterior flattens, suggesting the generator can complete titles using its parametric knowledge without depending on specific documents. This hypothesis is supported by evidence where a BART-only baseline successfully completes titles from partial decoding.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"What are the key finds of this paper?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0d73c0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This paper discusses RAG (Retrieval-Augmented Generation) models, evaluating their performance in tasks like Jeopardy question generation and fact verification. It compares RAG models against BART, highlighting RAG's ability to generate more factual and specific responses. The paper also explores how these models leverage both parametric knowledge and non-parametric memory for completing generations.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"What is this paper about?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46ae6ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am sorry, but the provided context does not contain the abstract of the paper. It includes discussions about model performance, generation diversity, specific examples, and references, but not a summary of the entire paper.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"What is the abstract of this paper?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5153dd61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is the main contribution of this paper?\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Retrieved Chunk 1:\n",
      "speciﬁc by a large margin. Table 3 shows typical generations from each model.\n",
      "Jeopardy questions often contain two separate pieces of information, and RAG-Token may perform\n",
      "best because it can generate responses that combine content from several documents. Figure 2 shows\n",
      "an example. When generating “Sun”, the posterior is high for document 2 which mentions “The\n",
      "Sun Also Rises”. Similarly, document 1 dominates the posterior when “A Farewell to Arms” is\n",
      "generated. Intriguingly, after the ﬁrst toke\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Retrieved Chunk 2:\n",
      "2020. URL https://arxiv.org/abs/2004.07159.\n",
      "[5] Danqi Chen, Adam Fisch, Jason Weston, and Antoine Bordes. Reading Wikipedia to Answer\n",
      "Open-Domain Questions. In Proceedings of the 55th Annual Meeting of the Association for\n",
      "Computational Linguistics (Volume 1: Long Papers), pages 1870–1879, Vancouver, Canada,\n",
      "July 2017. Association for Computational Linguistics. doi: 10.18653/v1/P17-1171. URL\n",
      "https://www.aclweb.org/anthology/P17-1171.\n",
      "[6] Eunsol Choi, Daniel Hewlett, Jakob Uszkoreit, Illia Polosuk\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Retrieved Chunk 3:\n",
      "Processing Systems 32, pages 3261–3275. Curran Associates, Inc., 2019. URL https://\n",
      "arxiv.org/abs/1905.00537.\n",
      "[62] Shuohang Wang, Mo Yu, Xiaoxiao Guo, Zhiguo Wang, Tim Klinger, Wei Zhang, Shiyu Chang,\n",
      "Gerry Tesauro, Bowen Zhou, and Jing Jiang. R3: Reinforced ranker-reader for open-domain\n",
      "question answering. In Sheila A. McIlraith and Kilian Q. Weinberger, editors, Proceedings of\n",
      "the Thirty-Second AAAI Conference on Artiﬁcial Intelligence, (AAAI-18), the 30th innovative\n",
      "Applications of Artiﬁcial \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Retrieved Chunk 4:\n",
      "This observation suggests that the generator can complete the titles without depending on speciﬁc\n",
      "documents. In other words, the model’s parametric knowledge is sufﬁcient to complete the titles. We\n",
      "ﬁnd evidence for this hypothesis by feeding the BART-only baseline with the partial decoding\"The\n",
      "Sun. BART completes the generation \"The Sun Also Rises\" is a novel by this author of \"The Sun\n",
      "Also Rises\" indicating the title \"The Sun Also Rises\" is stored in BART’s parameters. Similarly,\n",
      "BART will comp\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Retrieved Chunk 5:\n",
      "RAG-S This 14th century work is divided into 3 sections: \"Inferno\", \"Purgatorio\" & \"Paradiso\"\n",
      "For 2-way classiﬁcation, we compare against Thorne and Vlachos [57], who train RoBERTa [35]\n",
      "to classify the claim as true or false given the gold evidence sentence. RAG achieves an accuracy\n",
      "within 2.7% of this model, despite being supplied with only the claim and retrieving its own evidence.\n",
      "We also analyze whether documents retrieved by RAG correspond to documents annotated as gold\n",
      "evidence in FEVER. W\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test what chunks are being retrieved\n",
    "query = \"What is the main contribution of this paper?\"\n",
    "\n",
    "# See what the retriever finds\n",
    "retrieved_docs = retriever.invoke(query)\n",
    "\n",
    "print(f\"Query: {query}\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i, doc in enumerate(retrieved_docs, 1):\n",
    "    print(f\"\\nRetrieved Chunk {i}:\")\n",
    "    print(doc.page_content[:500])\n",
    "    print(\"\\n\" + \"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ce389d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First page content:\n",
      "Retrieval-Augmented Generation for\n",
      "Knowledge-Intensive NLP Tasks\n",
      "Patrick Lewis†‡, Ethan Perez⋆,\n",
      "Aleksandra Piktus†, Fabio Petroni†, Vladimir Karpukhin†, Naman Goyal†, Heinrich Küttler†,\n",
      "Mike Lewis†, Wen-tau Yih†, Tim Rocktäschel†‡, Sebastian Riedel†‡, Douwe Kiela†\n",
      "†Facebook AI Research;‡University College London;⋆New York University;\n",
      "plewis@fb.com\n",
      "Abstract\n",
      "Large pre-trained language models have been shown to store factual knowledge\n",
      "in their parameters, and achieve state-of-the-art results when ﬁne-tuned on down-\n",
      "stream NLP tasks. However, their ability to access and precisely manipulate knowl-\n",
      "edge is still limited, and hence on knowledge-intensive tasks, their performance\n",
      "lags behind task-speciﬁc architectures. Additionally, providing provenance for their\n",
      "decisions and updating their world knowledge remain open research problems. Pre-\n",
      "trained models with a differentiable access mechanism to explicit non-parametric\n",
      "memory have so far been only investigated for extractive downstream tas\n"
     ]
    }
   ],
   "source": [
    "print(\"First page content:\")\n",
    "print(pages[0].page_content[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f851de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Chunk 0:\n",
      "Length: 928 characters\n",
      "Content preview:\n",
      "Retrieval-Augmented Generation for\n",
      "Knowledge-Intensive NLP Tasks\n",
      "Patrick Lewis†‡, Ethan Perez⋆,\n",
      "Aleksandra Piktus†, Fabio Petroni†, Vladimir Karpukhin†, Naman Goyal†, Heinrich Küttler†,\n",
      "Mike Lewis†, Wen-tau Yih†, Tim Rocktäschel†‡, Sebastian Riedel†‡, Douwe Kiela†\n",
      "†Facebook AI Research;‡University C\n",
      "\n",
      "================================================================================\n",
      "Chunk 1:\n",
      "Length: 955 characters\n",
      "Content preview:\n",
      "edge is still limited, and hence on knowledge-intensive tasks, their performance\n",
      "lags behind task-speciﬁc architectures. Additionally, providing provenance for their\n",
      "decisions and updating their world knowledge remain open research problems. Pre-\n",
      "trained models with a differentiable access mechanism\n",
      "\n",
      "================================================================================\n",
      "Chunk 2:\n",
      "Length: 923 characters\n",
      "Content preview:\n",
      "ory for language generation. We introduce RAG models where the parametric\n",
      "memory is a pre-trained seq2seq model and the non-parametric memory is a dense\n",
      "vector index of Wikipedia, accessed with a pre-trained neural retriever. We com-\n",
      "pare two RAG formulations, one which conditions on the same retrie\n",
      "\n",
      "================================================================================\n",
      "Chunk 3:\n",
      "Length: 955 characters\n",
      "Content preview:\n",
      "outperforming parametric seq2seq models and task-speciﬁc retrieve-and-extract\n",
      "architectures. For language generation tasks, we ﬁnd that RAG models generate\n",
      "more speciﬁc, diverse and factual language than a state-of-the-art parametric-only\n",
      "seq2seq baseline.\n",
      "1 Introduction\n",
      "Pre-trained neural language \n",
      "\n",
      "================================================================================\n",
      "Chunk 4:\n",
      "Length: 620 characters\n",
      "Content preview:\n",
      "sides: They cannot easily expand or revise their memory, can’t straightforwardly provide insight into\n",
      "their predictions, and may produce “hallucinations” [ 38]. Hybrid models that combine parametric\n",
      "memory with non-parametric (i.e., retrieval-based) memories [20, 26, 48] can address some of these\n",
      "is\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Chunk {i}:\")\n",
    "    print(f\"Length: {len(chunks[i].page_content)} characters\")\n",
    "    print(f\"Content preview:\\n{chunks[i].page_content[:300]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
