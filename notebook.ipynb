{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30005882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Loading environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Fetching the API key\n",
    "gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "# Verifing the key loaded\n",
    "print(\"API Key loaded successfully!\" if gemini_api_key else \"API Key not found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60723633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini LLM initialized!\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# Initializing Gemini\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\", \n",
    "    google_api_key=gemini_api_key,\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "print(\"Gemini LLM initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "223f877d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 28 pages\n",
      "\n",
      "First page content preview:\n",
      "Retrieval-Augmented Generation for\n",
      "Knowledge-Intensive NLP Tasks\n",
      "Patrick Lewis†‡, Ethan Perez⋆,\n",
      "Aleksandra Piktus†, Fabio Petroni†, Vladimir Karpukhin†, Naman Goyal†, Heinrich Küttler†,\n",
      "Mike Lewis†, Wen-tau Yih†, Tim Rocktäschel†‡, Sebastian Riedel†‡, Douwe Kiela†\n",
      "†Facebook AI Research;‡University College London;⋆New York University;\n",
      "plewis@fb.com\n",
      "Abstract\n",
      "Large pre-trained language models have been shown to store factual knowledge\n",
      "in their parameters, and achieve state-of-the-art results when ﬁ...\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "pdf_path = \"testPaper.pdf\" \n",
    "loader = PyPDFLoader(pdf_path)\n",
    "\n",
    "pages = loader.load_and_split()\n",
    "\n",
    "print(f\"Loaded {len(pages)} pages\\n\")\n",
    "print(f\"First page content preview:\\n{pages[0].page_content[:500]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c87ae9e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chunks - 96\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Creating a text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,        # chars per chunk\n",
    "    chunk_overlap=200,      # overlap between chunks\n",
    "    length_function=len,\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(pages)\n",
    "print(f\"total chunks - {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41664e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wc/rfc_yx2d3m3dt9v_17z_88fm0000gn/T/ipykernel_93106/1913866116.py:5: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  HuggingFaceembeddingsModel = HuggingFaceEmbeddings(\n",
      "/Users/atharvadhumal/Documents/MyCodingDocs/GitHub projects/Rough Work/Research Paper Analyzer - RAG Model/myVenv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings created\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# Initializing embeddings model\n",
    "HuggingFaceembeddingsModel = HuggingFaceEmbeddings(\n",
    "       model_name=\"all-MiniLM-L6-v2\"  # Fast, lightweight model\n",
    "   )\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=HuggingFaceembeddingsModel,\n",
    "    persist_directory=\"./chromadb\"\n",
    ")\n",
    "\n",
    "print(\"embeddings created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1173a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of embeddings created: 96\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of embeddings created: {vectorstore._collection.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a439f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieval-Augmented Generation for\n",
      "Knowledge-Intensive NLP Tasks\n",
      "Patrick Lewis†‡, Ethan Perez⋆,\n",
      "Aleksandra Piktus†, Fabio Petroni†, Vladimir Karpukhin†, Naman Goyal†, Heinrich Küttler†,\n",
      "Mike Lewis†, W\n",
      "\n",
      "Embedding dimension: 384\n",
      "First 5 values: [-0.06688090413808823, -0.03467119485139847, -0.026010597124695778, 0.08180363476276398, 0.01612071320414543]\n"
     ]
    }
   ],
   "source": [
    "# Testing embeddings\n",
    "print(chunks[0].page_content[:200])\n",
    "sample_embedding = HuggingFaceembeddingsModel.embed_query(chunks[0].page_content)\n",
    "\n",
    "print(f\"\\nEmbedding dimension: {len(sample_embedding)}\")\n",
    "print(f\"First 5 values: {sample_embedding[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bc3444",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
